+++
title = "Texture-like representation of objects in human visual cortex"
date = 2021-11-04T00:00:00

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["**Akshay V. Jagadeesh**", "Justin L. Gardner"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference proceedings
# 2 = Journal
# 3 = Work in progress
# 4 = Technical report
# 5 = Book
# 6 = Book chapter
publication_types = ["2"]

# Publication name and optional abbreviated version.
publication = "In *Review*"
publication_short = "In *Review*"

# Abstract and optional shortened version.
abstract = "Humans can easily and quickly identify objects. This ability is widely thought to be supported by representations in ventral temporal cortex (VTC). However, prior evidence for this claim has not sufficiently distinguished whether VTC specifically represents objects or simply represents complex visual features regardless of spatial arrangement, i.e. texture. If it is the case that VTC directly supports object perception, one would expect that human performance discriminating objects from textures with scrambled object features would be predicted by the representational geometry of VTC. To test this claim, we leveraged an image synthesis approach that, unlike previous methods, provides independent control over the complexity and the spatial arrangement of visual features. In a conventional categorization task, we indeed find that VTC responses predict human behavior. However, in a perceptual task where subjects discriminated real objects from synthesized textures containing matching features in a scrambled arrangement, VTC representations failed to predict human performance. Whereas human observers were highly sensitive in detecting the real object, VTC representations were sensitive only to the complexity of features but not to their spatial arrangement, and therefore were unable to identify the real object amidst textures with matching features. We find the same insensitivity to feature arrangement and inability to predict human performance in a model of macaque inferotemporal cortex and in Imagenet-trained deep convolutional neural networks. These results suggest that representations in human VTC and state-of-the-art visual recognition models are unable to directly predict perception. How then might texture-like representations in VTC support object perception? We found that a category-specific linear readout of VTC yielded a representation that was more selective for natural feature arrangement, demonstrating that the information necessary to directly support object perception is accessible, though it requires prior experience and additional neural computation. Taken together, our results suggest that the role of human VTC is not to explicitly encode a fixed set of objects but rather to provide a basis set of texture-like features that can be infinitely reconfigured to flexibly learn and identify new object categories."

# Featured image thumbnail (optional)
image_preview = ""

# Is this a selected publication? (true/false)
selected = true

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter the filename (excluding '.md') of your project file in `content/project/`.
#projects = ["example-external-project"]

# Links (optional).
url_pdf = ""
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = ""
url_slides = ""
url_video = ""
url_poster = ""
url_source = ""

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
#url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Does the content use math formatting?
math = true

# Does the content use source code highlighting?
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
[header]
image = "headers/bubbles-wide.jpg"
caption = "My caption :smile:"

+++

